


<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>How to Use LLMs from Different LLM Providers &#8212; PyAgentSpec 26.1.0.dev0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dba54f56160742ef5599" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dba54f56160742ef5599" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.4cbf315f70debaebd550c87a6162cf0f.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css-style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/core.css" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=dba54f56160742ef5599"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dba54f56160742ef5599" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dba54f56160742ef5599" />

  
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/fix-navigation.js"></script>
    <script src="../_static/js/fix-navigation.js"></script>
    <script src="../_static/design-tabs.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'howtoguides/howto_llm_from_different_providers';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://oracle.github.io/agent-spec/switcher.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'dev';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
  <script src="../_static/announcement.js"></script>

    <link rel="icon" href="../_static/favicon.svg"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="How to Specify the Generation Configuration when Using LLMs" href="howto_generation_config.html" />
    <link rel="prev" title="How to Execute Agent Spec Across Frameworks" href="howto_execute_agentspec_across_frameworks.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="26.1" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/agentspec-dark.svg" class="logo__image only-light" alt="PyAgentSpec 26.1.0.dev0 documentation - Home"/>
    <img src="../_static/agentspec-white.svg" class="logo__image only-dark pst-js-only" alt="PyAgentSpec 26.1.0.dev0 documentation - Home"/>
  
  
</a></div>
    
      <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    <li class="nav-item ">
        <a class="nav-link nav-internal" href="../docs_home.html">Open Agent Spec</a>
    </li>
    <li class="nav-item ">
        <a class="nav-link nav-internal" href="../agentspec/index.html">Specification</a>
    </li>
    <li class="nav-item ">
        <a class="nav-link nav-internal" href="../api/index.html">API Reference</a>
    </li>
    <li class="nav-item ">
        <a class="nav-link nav-internal" href="../changelog.html">Release Notes</a>
    </li>
    <li class="nav-item ">
        <a class="nav-link nav-internal" href="../adapters/langgraph.html">Adapters</a>
    </li>
    <li class="nav-item ">
        <a class="nav-link nav-internal" href="../ecosystem/integrations.html">Ecosystem</a>
    </li>
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/oracle/agent-spec" title="WayFlow GitHub repository" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><img src="../_static/icons/github-icon.svg" class="icon-link-image" alt="WayFlow GitHub repository"/></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    <li class="nav-item ">
        <a class="nav-link nav-internal" href="../docs_home.html">Open Agent Spec</a>
    </li>
    <li class="nav-item ">
        <a class="nav-link nav-internal" href="../agentspec/index.html">Specification</a>
    </li>
    <li class="nav-item ">
        <a class="nav-link nav-internal" href="../api/index.html">API Reference</a>
    </li>
    <li class="nav-item ">
        <a class="nav-link nav-internal" href="../changelog.html">Release Notes</a>
    </li>
    <li class="nav-item ">
        <a class="nav-link nav-internal" href="../adapters/langgraph.html">Adapters</a>
    </li>
    <li class="nav-item ">
        <a class="nav-link nav-internal" href="../ecosystem/integrations.html">Ecosystem</a>
    </li>
  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/oracle/agent-spec" title="WayFlow GitHub repository" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><img src="../_static/icons/github-icon.svg" class="icon-link-image" alt="WayFlow GitHub repository"/></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Agent Spec</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../agentspec/index.html">Agent Spec Specification</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../agentspec/intro_and_motivation.html">Introduction, motivation &amp; vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agentspec/language_spec_25_4_1.html">Language specification (v25.4.1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agentspec/positioning.html">Positioning in the agentic ecosystem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agentspec/tracing.html">Tracing</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Essentials</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">How-to guides</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="howto_agents.html">How to build a simple ReAct Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="howto_mcp.html">How to connect MCP tools to assistants</a></li>
<li class="toctree-l2"><a class="reference internal" href="howto_flow_with_conditional_branches.html">How to Develop a Flow with Conditional Branches</a></li>
<li class="toctree-l2"><a class="reference internal" href="howto_agent_with_remote_tools.html">How to Develop an Agent with Remote Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="howto_mapnode.html">Do Map and Reduce Operations in Flows</a></li>
<li class="toctree-l2"><a class="reference internal" href="howto_orchestrator_agent.html">How to Build an Orchestrator-Workers Agents Pattern</a></li>
<li class="toctree-l2"><a class="reference internal" href="howto_ociagent.html">Use OCI Generative AI Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="howto_a2aagent.html">Use an A2A Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="howto_swarm.html">Build a Swarm of Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="howto_managerworkers.html">Build a Manager-Worker Multi-Agent System</a></li>
<li class="toctree-l2"><a class="reference internal" href="howto_structured_generation.html">Build Flows with Structured LLM Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="howto_parallelflownode.html">Run Multiple Flows in Parallel</a></li>
<li class="toctree-l2"><a class="reference internal" href="howto_execute_agentspec_with_wayflow.html">How to Execute Agent Spec Configuration with WayFlow</a></li>
<li class="toctree-l2"><a class="reference internal" href="howto_execute_agentspec_across_frameworks.html">How to Execute Agent Spec Across Frameworks</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Use LLM from Different LLM Sources and Providers</a></li>
<li class="toctree-l2"><a class="reference internal" href="howto_generation_config.html">Specify the Generation Configuration when Using LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="howto_disaggregated_config.html">How to Use Disaggregated Config</a></li>
<li class="toctree-l2"><a class="reference internal" href="howto_ag_ui.html">How to Use AG-UI with Agent Spec</a></li>
<li class="toctree-l2"><a class="reference internal" href="howto_plugin.html">How to use custom components with the Plugin System</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">API Reference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/components.html">Components</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/agent.html">Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/remoteagent.html">Remote Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/flows.html">Flows &amp; Nodes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/llmmodels.html">LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/tools.html">Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/ioproperties.html">IO Properties</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/mcp.html">MCP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/serialization.html">Serialization / Deserialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/agenticpatterns.html">Agentic Patterns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/agent_specialization.html">Agent Specialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/a2a.html">A2A</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/adapters.html">Adapters</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Adapters</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../adapters/langgraph.html">LangGraph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../adapters/wayflow.html">WayFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../adapters/crewai.html">CrewAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../adapters/autogen.html">AutoGen</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ecosystem</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ecosystem/integrations.html">Integrations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ecosystem/collaborations.html">Collaborations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../misc/glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../misc/reference_sheet.html">Reference Sheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../security.html">Security Considerations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faqs.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Release Notes</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../docs_home.html" class="nav-link">Open Agent Specification (Agent Spec)</a></li>
    
    
    <li class="breadcrumb-item"><a href="index.html" class="nav-link">How-to Guides</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">How to Use LLMs from Different LLM Providers</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="how-to-use-llms-from-different-llm-providers">
<h1>How to Use LLMs from Different LLM Providers<a class="headerlink" href="#how-to-use-llms-from-different-llm-providers" title="Permalink to this heading">#</a></h1>
<p>Agent Spec supports several LLM providers, each one having its own LlmConfig component.
The available LLMs are:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../api/llmmodels.html#openaiconfig"><span class="std std-ref">OpenAiConfig</span></a></p></li>
<li><p><a class="reference internal" href="../api/llmmodels.html#ocigenaiconfig"><span class="std std-ref">OciGenAiConfig</span></a></p></li>
<li><p><a class="reference internal" href="../api/llmmodels.html#openaicompatibleconfig"><span class="std std-ref">OpenAiCompatibleConfig</span></a></p></li>
<li><p><a class="reference internal" href="../api/llmmodels.html#vllmconfig"><span class="std std-ref">VllmConfig</span></a></p></li>
<li><p><a class="reference internal" href="../api/llmmodels.html#ollamaconfig"><span class="std std-ref">OllamaConfig</span></a></p></li>
</ul>
<p>Their configuration is specified directly in their respective class constructor.
This guide will show you how to configure LLMs from different LLM providers with examples and notes on usage.</p>
<section id="ocigenaiconfig">
<h2>OciGenAiConfig<a class="headerlink" href="#ocigenaiconfig" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://docs.oracle.com/iaas/Content/generative-ai/overview.htm">OCI GenAI Configuration</a> refers to model served
by <a class="reference external" href="https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/">OCI Generative AI</a>.</p>
<p><strong>Parameters</strong></p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-model_id">
<span id="cmdoption-arg-model-id"></span><span class="sig-name descname"><span class="pre">model_id:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><a class="headerlink" href="#cmdoption-arg-model_id" title="Permalink to this definition">#</a></dt>
<dd><p>Name of the model to use. A list of the available models is given in
<a class="reference external" href="https://docs.oracle.com/en-us/iaas/Content/generative-ai/deprecating.htm#">Oracle OCI Documentation</a>
under the Model Retirement Dates (On-Demand Mode) section.</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-compartment_id">
<span id="cmdoption-arg-compartment-id"></span><span class="sig-name descname"><span class="pre">compartment_id:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><a class="headerlink" href="#cmdoption-arg-compartment_id" title="Permalink to this definition">#</a></dt>
<dd><p>The OCID (Oracle Cloud Identifier) of a compartment within your tenancy.</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-serving_mode">
<span id="cmdoption-arg-serving-mode"></span><span class="sig-name descname"><span class="pre">serving_mode:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><a class="headerlink" href="#cmdoption-arg-serving_mode" title="Permalink to this definition">#</a></dt>
<dd><p>The mode how the model specified is served:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ON_DEMAND</span></code>: the model is hosted in a shared environment;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DEDICATED</span></code>: the model is deployed in a customer-dedicated environment.</p></li>
</ul>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-default_generation_parameters">
<span id="cmdoption-arg-default-generation-parameters"></span><span id="cmdoption-arg-null"></span><span class="sig-name descname"><span class="pre">default_generation_parameters:</span></span><span class="sig-prename descclassname"> <span class="pre">dict</span></span><span class="sig-prename descclassname"><span class="pre">,</span> </span><span class="sig-name descname"><span class="pre">null</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-default_generation_parameters" title="Permalink to this definition">#</a></dt>
<dd><p>Default parameters for text generation with this model.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">default_generation_parameters</span> <span class="o">=</span> <span class="n">LlmGenerationConfig</span><span class="p">(</span><span class="n">max_tokens</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-client_config">
<span id="cmdoption-arg-client-config"></span><span id="cmdoption-arg-0"></span><span class="sig-name descname"><span class="pre">client_config:</span></span><span class="sig-prename descclassname"> <span class="pre">OciClientConfig</span></span><span class="sig-prename descclassname"><span class="pre">,</span> </span><span class="sig-name descname"><span class="pre">null</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-client_config" title="Permalink to this definition">#</a></dt>
<dd><p>OCI client config to authenticate the OCI service.
See the below examples for the usage and more information.</p>
</dd></dl>

<section id="oci-client-configuration">
<h3>OCI Client Configuration<a class="headerlink" href="#oci-client-configuration" title="Permalink to this heading">#</a></h3>
<p>OCI GenAI models require a client configuration that contains all the settings needed to perform
the authentication to use OCI services. The <code class="docutils literal notranslate"><span class="pre">OciClientConfig</span></code> holds these settings.</p>
<p><strong>Parameters</strong></p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-service_endpoint">
<span id="cmdoption-arg-service-endpoint"></span><span class="sig-name descname"><span class="pre">service_endpoint:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><a class="headerlink" href="#cmdoption-arg-service_endpoint" title="Permalink to this definition">#</a></dt>
<dd><p>The endpoint URL for the OCIGenAI service. Make sure you set the region right.
For doing so, make sure that the Region where your private key is created,
is aligned with the region mention in the <code class="docutils literal notranslate"><span class="pre">service_endpoint</span></code>.</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-auth_type">
<span id="cmdoption-arg-auth-type"></span><span class="sig-name descname"><span class="pre">auth_type:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><a class="headerlink" href="#cmdoption-arg-auth_type" title="Permalink to this definition">#</a></dt>
<dd><p>The authentication type to use, e.g., <code class="docutils literal notranslate"><span class="pre">API_KEY</span></code>,
<code class="docutils literal notranslate"><span class="pre">SECURITY_TOKEN</span></code>,
<code class="docutils literal notranslate"><span class="pre">INSTANCE_PRINCIPAL</span></code> (It means that you need to execute the code from a compartment enabled for OCIGenAI.),
<code class="docutils literal notranslate"><span class="pre">RESOURCE_PRINCIPAL</span></code>.</p>
</dd></dl>

<p>Based on the type of authentication the user wants to adopt, different specifications of the <code class="docutils literal notranslate"><span class="pre">OciClientConfig</span></code>
are defined. Indeed, the <code class="docutils literal notranslate"><span class="pre">OciClientConfig</span></code> component is abstract, and should not be used directly.
In the following sections we show what client extensions are available and their specific parameters.</p>
<p><strong>Examples</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyagentspec.llms</span><span class="w"> </span><span class="kn">import</span> <span class="n">OciGenAiConfig</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyagentspec.llms</span><span class="w"> </span><span class="kn">import</span> <span class="n">LlmGenerationConfig</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyagentspec.llms.ociclientconfig</span><span class="w"> </span><span class="kn">import</span> <span class="n">OciClientConfigWithApiKey</span>

<span class="c1"># Get the list of available models from:</span>
<span class="c1"># https://docs.oracle.com/en-us/iaas/Content/generative-ai/deprecating.htm#</span>
<span class="c1"># under the &quot;Model Retirement Dates (On-Demand Mode)&quot; section.</span>
<span class="n">OCIGENAI_MODEL_ID</span> <span class="o">=</span> <span class="s2">&quot;xai.grok-3&quot;</span>
<span class="c1"># Typical service endpoint for OCI GenAI service inference</span>
<span class="c1"># &lt;oci region&gt; can be &quot;us-chicago-1&quot; and can also be found in your ~/.oci/config file</span>
<span class="n">OCIGENAI_ENDPOINT</span> <span class="o">=</span> <span class="s2">&quot;https://inference.generativeai.&lt;oci region&gt;.oci.oraclecloud.com&quot;</span>
<span class="c1"># &lt;compartment_id&gt; can be obtained from your personal OCI account (not the key config file).</span>
<span class="c1"># Please find it under &quot;Identity &gt; Compartments&quot; on the OCI console website after logging in to your user account.</span>
<span class="n">COMPARTMENT_ID</span> <span class="o">=</span> <span class="s2">&quot;ocid1.compartment.oc1..&lt;compartment_id&gt;&quot;</span>

<span class="n">generation_config</span> <span class="o">=</span> <span class="n">LlmGenerationConfig</span><span class="p">(</span><span class="n">max_tokens</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">OciGenAiConfig</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;oci-genai-grok3&quot;</span><span class="p">,</span>
    <span class="n">model_id</span><span class="o">=</span><span class="n">OCIGENAI_MODEL_ID</span><span class="p">,</span>
    <span class="n">compartment_id</span><span class="o">=</span><span class="n">COMPARTMENT_ID</span><span class="p">,</span>
    <span class="n">client_config</span><span class="o">=</span><span class="n">OciClientConfigWithApiKey</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;client_config&quot;</span><span class="p">,</span>
        <span class="n">service_endpoint</span><span class="o">=</span><span class="n">OCIGENAI_ENDPOINT</span><span class="p">,</span>
        <span class="n">auth_file_location</span><span class="o">=</span><span class="s2">&quot;~/.oci/config&quot;</span><span class="p">,</span>
        <span class="n">auth_profile</span><span class="o">=</span><span class="s2">&quot;DEFAULT&quot;</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">default_generation_parameters</span><span class="o">=</span><span class="n">generation_config</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="ociclientconfigwithsecuritytoken">
<h3>OciClientConfigWithSecurityToken<a class="headerlink" href="#ociclientconfigwithsecuritytoken" title="Permalink to this heading">#</a></h3>
<p>Client configuration that should be used if users want to use authentication through security token.</p>
<p><strong>Parameters</strong></p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-auth_file_location">
<span id="cmdoption-arg-auth-file-location"></span><span class="sig-name descname"><span class="pre">auth_file_location:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><a class="headerlink" href="#cmdoption-arg-auth_file_location" title="Permalink to this definition">#</a></dt>
<dd><p>The location of the authentication file from which the authentication information should be retrieved.
The default location is <code class="docutils literal notranslate"><span class="pre">~/.oci/config</span></code>.</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-auth_profile">
<span id="cmdoption-arg-auth-profile"></span><span class="sig-name descname"><span class="pre">auth_profile:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><a class="headerlink" href="#cmdoption-arg-auth_profile" title="Permalink to this definition">#</a></dt>
<dd><p>The name of the profile to use, among the ones defined in the authentication file.
The default profile name is <code class="docutils literal notranslate"><span class="pre">DEFAULT</span></code>.</p>
</dd></dl>

</section>
<section id="ociclientconfigwithapikey">
<h3>OciClientConfigWithApiKey<a class="headerlink" href="#ociclientconfigwithapikey" title="Permalink to this heading">#</a></h3>
<p>Client configuration that should be used if users want to use authentication with API key.
The parameters required are the same defined for the <code class="docutils literal notranslate"><span class="pre">OciClientConfigWithSecurityToken</span></code>.</p>
</section>
<section id="ociclientconfigwithinstanceprincipal">
<h3>OciClientConfigWithInstancePrincipal<a class="headerlink" href="#ociclientconfigwithinstanceprincipal" title="Permalink to this heading">#</a></h3>
<p>Client configuration that should be used if users want to use instance principal authentication.
No additional parameters are required.</p>
</section>
<section id="ociclientconfigwithresourceprincipal">
<h3>OciClientConfigWithResourcePrincipal<a class="headerlink" href="#ociclientconfigwithresourceprincipal" title="Permalink to this heading">#</a></h3>
<p>Client configuration that should be used if users want to use resource principal authentication.
No additional parameters are required.</p>
</section>
</section>
<section id="openaiconfig">
<h2>OpenAiConfig<a class="headerlink" href="#openaiconfig" title="Permalink to this heading">#</a></h2>
<p>OpenAI Models are powered by <a class="reference external" href="https://platform.openai.com/docs/models">OpenAI</a>.
You can refer to one of those models by using the <code class="docutils literal notranslate"><span class="pre">OpenAiConfig</span></code> Component.</p>
<p><strong>Parameters</strong></p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-1">
<span class="sig-name descname"><span class="pre">model_id:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><a class="headerlink" href="#cmdoption-arg-1" title="Permalink to this definition">#</a></dt>
<dd><p>Name of the model to use.</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-api_type">
<span id="cmdoption-arg-api-type"></span><span class="sig-name descname"><span class="pre">api_type:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><a class="headerlink" href="#cmdoption-arg-api_type" title="Permalink to this definition">#</a></dt>
<dd><p>The API type that should be used. Can be either <code class="docutils literal notranslate"><span class="pre">chat_completions</span></code> or <code class="docutils literal notranslate"><span class="pre">responses</span></code>.</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-api_key">
<span id="cmdoption-arg-api-key"></span><span id="cmdoption-arg-2"></span><span class="sig-name descname"><span class="pre">api_key:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><span class="sig-prename descclassname"><span class="pre">,</span> </span><span class="sig-name descname"><span class="pre">null</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-api_key" title="Permalink to this definition">#</a></dt>
<dd><p>An optional api key for the authentication with the OpenAI endpoint.</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-3">
<span id="cmdoption-arg-4"></span><span class="sig-name descname"><span class="pre">default_generation_parameters:</span></span><span class="sig-prename descclassname"> <span class="pre">dict</span></span><span class="sig-prename descclassname"><span class="pre">,</span> </span><span class="sig-name descname"><span class="pre">null</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-3" title="Permalink to this definition">#</a></dt>
<dd><p>Default parameters for text generation with this model.</p>
</dd></dl>

<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Ensure that the <code class="docutils literal notranslate"><span class="pre">OPENAI_API_KEY</span></code> is set beforehand
to access this model. A list of available OpenAI models can be found at
the following link: <a class="reference external" href="https://platform.openai.com/docs/models">OpenAI Models</a>.</p>
</div>
<p><strong>Examples</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyagentspec.llms</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAiConfig</span>

<span class="n">generation_config</span> <span class="o">=</span> <span class="n">LlmGenerationConfig</span><span class="p">(</span><span class="n">max_tokens</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAiConfig</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;openai-gpt-5&quot;</span><span class="p">,</span>
    <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;gpt-5&quot;</span><span class="p">,</span>
    <span class="n">default_generation_parameters</span><span class="o">=</span><span class="n">generation_config</span><span class="p">,</span>
    <span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;optional_api_key&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="openaicompatibleconfig">
<h2>OpenAiCompatibleConfig<a class="headerlink" href="#openaicompatibleconfig" title="Permalink to this heading">#</a></h2>
<p>OpenAI Compatible LLMs are all those models that are served through OpenAI APIs, either responses or completions.
The <code class="docutils literal notranslate"><span class="pre">OpenAiCompatibleConfig</span></code> allows users to use this type of models in their agents and flows.</p>
<p><strong>Parameters</strong></p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-5">
<span class="sig-name descname"><span class="pre">model_id:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><a class="headerlink" href="#cmdoption-arg-5" title="Permalink to this definition">#</a></dt>
<dd><p>Name of the model to use.</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-url">
<span class="sig-name descname"><span class="pre">url:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><a class="headerlink" href="#cmdoption-arg-url" title="Permalink to this definition">#</a></dt>
<dd><p>Hostname and port of the vLLM server where the model is hosted.</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-6">
<span class="sig-name descname"><span class="pre">api_type:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><a class="headerlink" href="#cmdoption-arg-6" title="Permalink to this definition">#</a></dt>
<dd><p>The API type that should be used. Can be either <code class="docutils literal notranslate"><span class="pre">chat_completions</span></code> or <code class="docutils literal notranslate"><span class="pre">responses</span></code>.</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-7">
<span id="cmdoption-arg-8"></span><span class="sig-name descname"><span class="pre">api_key:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><span class="sig-prename descclassname"><span class="pre">,</span> </span><span class="sig-name descname"><span class="pre">null</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-7" title="Permalink to this definition">#</a></dt>
<dd><p>An optional api key if the remote server requires it.</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-9">
<span id="cmdoption-arg-10"></span><span class="sig-name descname"><span class="pre">default_generation_parameters:</span></span><span class="sig-prename descclassname"> <span class="pre">dict</span></span><span class="sig-prename descclassname"><span class="pre">,</span> </span><span class="sig-name descname"><span class="pre">null</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-9" title="Permalink to this definition">#</a></dt>
<dd><p>Default parameters for text generation with this model.</p>
</dd></dl>

<p><strong>Examples</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyagentspec.llms</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAiCompatibleConfig</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyagentspec.llms.openaicompatibleconfig</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAIAPIType</span>

<span class="n">generation_config</span> <span class="o">=</span> <span class="n">LlmGenerationConfig</span><span class="p">(</span><span class="n">max_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAiCompatibleConfig</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;vllm-llama-4-maverick&quot;</span><span class="p">,</span>
    <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;llama-4-maverick&quot;</span><span class="p">,</span>
    <span class="n">url</span><span class="o">=</span><span class="s2">&quot;http://url.to.my.vllm.server/llama4mav&quot;</span><span class="p">,</span>
    <span class="n">api_type</span><span class="o">=</span><span class="n">OpenAIAPIType</span><span class="o">.</span><span class="n">RESPONSES</span><span class="p">,</span>
    <span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;optional_api_key&quot;</span><span class="p">,</span>
    <span class="n">default_generation_parameters</span><span class="o">=</span><span class="n">generation_config</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="vllmconfig">
<h2>VllmConfig<a class="headerlink" href="#vllmconfig" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://docs.vllm.ai/en/latest/models/supported_models.html">vLLM Models</a> are models hosted with a vLLM server.
The <code class="docutils literal notranslate"><span class="pre">VllmConfig</span></code> allows users to use this type of models in their agents and flows.</p>
<p><strong>Parameters</strong></p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-11">
<span class="sig-name descname"><span class="pre">model_id:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><a class="headerlink" href="#cmdoption-arg-11" title="Permalink to this definition">#</a></dt>
<dd><p>Name of the model to use.</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-12">
<span class="sig-name descname"><span class="pre">url:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><a class="headerlink" href="#cmdoption-arg-12" title="Permalink to this definition">#</a></dt>
<dd><p>Hostname and port of the vLLM server where the model is hosted.</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-13">
<span class="sig-name descname"><span class="pre">api_type:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><a class="headerlink" href="#cmdoption-arg-13" title="Permalink to this definition">#</a></dt>
<dd><p>The API type that should be used. Can be either <code class="docutils literal notranslate"><span class="pre">chat_completions</span></code> or <code class="docutils literal notranslate"><span class="pre">responses</span></code>.</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-14">
<span id="cmdoption-arg-15"></span><span class="sig-name descname"><span class="pre">default_generation_parameters:</span></span><span class="sig-prename descclassname"> <span class="pre">dict</span></span><span class="sig-prename descclassname"><span class="pre">,</span> </span><span class="sig-name descname"><span class="pre">null</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-14" title="Permalink to this definition">#</a></dt>
<dd><p>Default parameters for text generation with this model.</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-16">
<span id="cmdoption-arg-17"></span><span class="sig-name descname"><span class="pre">api_key:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><span class="sig-prename descclassname"><span class="pre">,</span> </span><span class="sig-name descname"><span class="pre">null</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-16" title="Permalink to this definition">#</a></dt>
<dd><p>An optional api key if the remote vllm server requires it.</p>
</dd></dl>

<p><strong>Examples</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyagentspec.llms</span><span class="w"> </span><span class="kn">import</span> <span class="n">VllmConfig</span>

<span class="n">generation_config</span> <span class="o">=</span> <span class="n">LlmGenerationConfig</span><span class="p">(</span><span class="n">max_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">VllmConfig</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;vllm-llama-4-maverick&quot;</span><span class="p">,</span>
    <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;llama-4-maverick&quot;</span><span class="p">,</span>
    <span class="n">url</span><span class="o">=</span><span class="s2">&quot;http://url.to.my.vllm.server/llama4mav&quot;</span><span class="p">,</span>
    <span class="n">default_generation_parameters</span><span class="o">=</span><span class="n">generation_config</span><span class="p">,</span>
    <span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;optional_api_key&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="ollamaconfig">
<h2>OllamaConfig<a class="headerlink" href="#ollamaconfig" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://ollama.com/">Ollama Models</a> are powered by a locally hosted Ollama server.
The <code class="docutils literal notranslate"><span class="pre">OllamaConfig</span></code> allows users to use this type of models in their agents and flows.</p>
<p><strong>Parameters</strong></p>
<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-18">
<span class="sig-name descname"><span class="pre">model_id:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><a class="headerlink" href="#cmdoption-arg-18" title="Permalink to this definition">#</a></dt>
<dd><p>Name of the model to use.</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-19">
<span class="sig-name descname"><span class="pre">url:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><a class="headerlink" href="#cmdoption-arg-19" title="Permalink to this definition">#</a></dt>
<dd><p>Hostname and port of the vLLM server where the model is hosted.</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-20">
<span class="sig-name descname"><span class="pre">api_type:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><a class="headerlink" href="#cmdoption-arg-20" title="Permalink to this definition">#</a></dt>
<dd><p>The API type that should be used. Can be either <code class="docutils literal notranslate"><span class="pre">chat_completions</span></code> or <code class="docutils literal notranslate"><span class="pre">responses</span></code>.</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-21">
<span id="cmdoption-arg-22"></span><span class="sig-name descname"><span class="pre">default_generation_parameters:</span></span><span class="sig-prename descclassname"> <span class="pre">dict</span></span><span class="sig-prename descclassname"><span class="pre">,</span> </span><span class="sig-name descname"><span class="pre">null</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-21" title="Permalink to this definition">#</a></dt>
<dd><p>Default parameters for text generation with this model.</p>
</dd></dl>

<dl class="std option">
<dt class="sig sig-object std" id="cmdoption-arg-23">
<span id="cmdoption-arg-24"></span><span class="sig-name descname"><span class="pre">api_key:</span></span><span class="sig-prename descclassname"> <span class="pre">str</span></span><span class="sig-prename descclassname"><span class="pre">,</span> </span><span class="sig-name descname"><span class="pre">null</span></span><span class="sig-prename descclassname"></span><a class="headerlink" href="#cmdoption-arg-23" title="Permalink to this definition">#</a></dt>
<dd><p>An optional api key if the ollama server requires it.</p>
</dd></dl>

<p><strong>Examples</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyagentspec.llms</span><span class="w"> </span><span class="kn">import</span> <span class="n">OllamaConfig</span>

<span class="n">generation_config</span> <span class="o">=</span> <span class="n">LlmGenerationConfig</span><span class="p">(</span><span class="n">max_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">OllamaConfig</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;ollama-llama-4&quot;</span><span class="p">,</span>
    <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;llama-4-maverick&quot;</span><span class="p">,</span>
    <span class="n">url</span><span class="o">=</span><span class="s2">&quot;http://url.to.my.ollama.server/llama4mav&quot;</span><span class="p">,</span>
    <span class="n">default_generation_parameters</span><span class="o">=</span><span class="n">generation_config</span><span class="p">,</span>
    <span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;optional_api_key&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="recap">
<h2>Recap<a class="headerlink" href="#recap" title="Permalink to this heading">#</a></h2>
<p>This guide provides detailed descriptions of each model type supported by Agent Spec,
demonstrating how to declare them using PyAgentSpec syntax.</p>
<details class="summary-below-is-the-complete-code-from-this-guide">
<summary>Below is the complete code from this guide.</summary><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="kn">from</span><span class="w"> </span><span class="nn">pyagentspec.llms</span><span class="w"> </span><span class="kn">import</span> <span class="n">OciGenAiConfig</span>
<span class="linenos"> 2</span><span class="kn">from</span><span class="w"> </span><span class="nn">pyagentspec.llms</span><span class="w"> </span><span class="kn">import</span> <span class="n">LlmGenerationConfig</span>
<span class="linenos"> 3</span><span class="kn">from</span><span class="w"> </span><span class="nn">pyagentspec.llms.ociclientconfig</span><span class="w"> </span><span class="kn">import</span> <span class="n">OciClientConfigWithApiKey</span>
<span class="linenos"> 4</span>
<span class="linenos"> 5</span><span class="c1"># Get the list of available models from:</span>
<span class="linenos"> 6</span><span class="c1"># https://docs.oracle.com/en-us/iaas/Content/generative-ai/deprecating.htm#</span>
<span class="linenos"> 7</span><span class="c1"># under the &quot;Model Retirement Dates (On-Demand Mode)&quot; section.</span>
<span class="linenos"> 8</span><span class="n">OCIGENAI_MODEL_ID</span> <span class="o">=</span> <span class="s2">&quot;xai.grok-3&quot;</span>
<span class="linenos"> 9</span><span class="c1"># Typical service endpoint for OCI GenAI service inference</span>
<span class="linenos">10</span><span class="c1"># &lt;oci region&gt; can be &quot;us-chicago-1&quot; and can also be found in your ~/.oci/config file</span>
<span class="linenos">11</span><span class="n">OCIGENAI_ENDPOINT</span> <span class="o">=</span> <span class="s2">&quot;https://inference.generativeai.&lt;oci region&gt;.oci.oraclecloud.com&quot;</span>
<span class="linenos">12</span><span class="c1"># &lt;compartment_id&gt; can be obtained from your personal OCI account (not the key config file).</span>
<span class="linenos">13</span><span class="c1"># Please find it under &quot;Identity &gt; Compartments&quot; on the OCI console website after logging in to your user account.</span>
<span class="linenos">14</span><span class="n">COMPARTMENT_ID</span> <span class="o">=</span> <span class="s2">&quot;ocid1.compartment.oc1..&lt;compartment_id&gt;&quot;</span>
<span class="linenos">15</span>
<span class="linenos">16</span><span class="n">generation_config</span> <span class="o">=</span> <span class="n">LlmGenerationConfig</span><span class="p">(</span><span class="n">max_tokens</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="linenos">17</span>
<span class="linenos">18</span><span class="n">llm</span> <span class="o">=</span> <span class="n">OciGenAiConfig</span><span class="p">(</span>
<span class="linenos">19</span>    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;oci-genai-grok3&quot;</span><span class="p">,</span>
<span class="linenos">20</span>    <span class="n">model_id</span><span class="o">=</span><span class="n">OCIGENAI_MODEL_ID</span><span class="p">,</span>
<span class="linenos">21</span>    <span class="n">compartment_id</span><span class="o">=</span><span class="n">COMPARTMENT_ID</span><span class="p">,</span>
<span class="linenos">22</span>    <span class="n">client_config</span><span class="o">=</span><span class="n">OciClientConfigWithApiKey</span><span class="p">(</span>
<span class="linenos">23</span>        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;client_config&quot;</span><span class="p">,</span>
<span class="linenos">24</span>        <span class="n">service_endpoint</span><span class="o">=</span><span class="n">OCIGENAI_ENDPOINT</span><span class="p">,</span>
<span class="linenos">25</span>        <span class="n">auth_file_location</span><span class="o">=</span><span class="s2">&quot;~/.oci/config&quot;</span><span class="p">,</span>
<span class="linenos">26</span>        <span class="n">auth_profile</span><span class="o">=</span><span class="s2">&quot;DEFAULT&quot;</span><span class="p">,</span>
<span class="linenos">27</span>    <span class="p">),</span>
<span class="linenos">28</span>    <span class="n">default_generation_parameters</span><span class="o">=</span><span class="n">generation_config</span><span class="p">,</span>
<span class="linenos">29</span><span class="p">)</span>
<span class="linenos">30</span>
<span class="linenos">31</span><span class="kn">from</span><span class="w"> </span><span class="nn">pyagentspec.llms</span><span class="w"> </span><span class="kn">import</span> <span class="n">VllmConfig</span>
<span class="linenos">32</span>
<span class="linenos">33</span><span class="n">generation_config</span> <span class="o">=</span> <span class="n">LlmGenerationConfig</span><span class="p">(</span><span class="n">max_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="linenos">34</span>
<span class="linenos">35</span><span class="n">llm</span> <span class="o">=</span> <span class="n">VllmConfig</span><span class="p">(</span>
<span class="linenos">36</span>    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;vllm-llama-4-maverick&quot;</span><span class="p">,</span>
<span class="linenos">37</span>    <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;llama-4-maverick&quot;</span><span class="p">,</span>
<span class="linenos">38</span>    <span class="n">url</span><span class="o">=</span><span class="s2">&quot;http://url.to.my.vllm.server/llama4mav&quot;</span><span class="p">,</span>
<span class="linenos">39</span>    <span class="n">default_generation_parameters</span><span class="o">=</span><span class="n">generation_config</span><span class="p">,</span>
<span class="linenos">40</span><span class="p">)</span>
<span class="linenos">41</span>
<span class="linenos">42</span><span class="kn">from</span><span class="w"> </span><span class="nn">pyagentspec.llms</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAiConfig</span>
<span class="linenos">43</span>
<span class="linenos">44</span><span class="n">generation_config</span> <span class="o">=</span> <span class="n">LlmGenerationConfig</span><span class="p">(</span><span class="n">max_tokens</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="linenos">45</span>
<span class="linenos">46</span><span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAiConfig</span><span class="p">(</span>
<span class="linenos">47</span>    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;openai-gpt-5&quot;</span><span class="p">,</span>
<span class="linenos">48</span>    <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;gpt-5&quot;</span><span class="p">,</span>
<span class="linenos">49</span>    <span class="n">default_generation_parameters</span><span class="o">=</span><span class="n">generation_config</span><span class="p">,</span>
<span class="linenos">50</span><span class="p">)</span>
<span class="linenos">51</span>
<span class="linenos">52</span><span class="kn">from</span><span class="w"> </span><span class="nn">pyagentspec.llms</span><span class="w"> </span><span class="kn">import</span> <span class="n">OllamaConfig</span>
<span class="linenos">53</span>
<span class="linenos">54</span><span class="n">generation_config</span> <span class="o">=</span> <span class="n">LlmGenerationConfig</span><span class="p">(</span><span class="n">max_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="linenos">55</span>
<span class="linenos">56</span><span class="n">llm</span> <span class="o">=</span> <span class="n">OllamaConfig</span><span class="p">(</span>
<span class="linenos">57</span>    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;ollama-llama-4&quot;</span><span class="p">,</span>
<span class="linenos">58</span>    <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;llama-4-maverick&quot;</span><span class="p">,</span>
<span class="linenos">59</span>    <span class="n">url</span><span class="o">=</span><span class="s2">&quot;http://url.to.my.ollama.server/llama4mav&quot;</span><span class="p">,</span>
<span class="linenos">60</span>    <span class="n">default_generation_parameters</span><span class="o">=</span><span class="n">generation_config</span>
<span class="linenos">61</span><span class="p">)</span>
</pre></div>
</div>
</details></section>
<section id="next-steps">
<h2>Next steps<a class="headerlink" href="#next-steps" title="Permalink to this heading">#</a></h2>
<p>Having learned how to configure LLMs from different providers, you may now proceed to:</p>
<ul class="simple">
<li><p><a class="reference internal" href="howto_generation_config.html"><span class="doc">How to Build LLM Generation Configurations</span></a></p></li>
<li><p><a class="reference internal" href="howto_agent_with_remote_tools.html"><span class="doc">How to Build an Agent with Remote Tools</span></a></p></li>
</ul>
</section>
</section>


                </article>
              
              
              
              
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ocigenaiconfig">OciGenAiConfig</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#oci-client-configuration">OCI Client Configuration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ociclientconfigwithsecuritytoken">OciClientConfigWithSecurityToken</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ociclientconfigwithapikey">OciClientConfigWithApiKey</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ociclientconfigwithinstanceprincipal">OciClientConfigWithInstancePrincipal</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ociclientconfigwithresourceprincipal">OciClientConfigWithResourcePrincipal</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#openaiconfig">OpenAiConfig</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#openaicompatibleconfig">OpenAiCompatibleConfig</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vllmconfig">VllmConfig</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ollamaconfig">OllamaConfig</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#recap">Recap</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next steps</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=dba54f56160742ef5599"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=dba54f56160742ef5599"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
       Copyright 2025, Oracle and/or its affiliates..
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 6.1.0.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>