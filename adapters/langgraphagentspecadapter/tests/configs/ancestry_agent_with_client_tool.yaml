# This configuration has two inputs for the client tool
agents: []
component_type: Agent
description: ''
flows: []
id: bf1adb6e-e915-4a2d-a3e9-4b75a27fd01f
inputs: []
llm_config:
  component_type: VllmConfig
  default_generation_parameters: null
  description: null
  id: d60ddfad-e086-498b-97da-ad35296a6ec4
  metadata:
    __metadata_info__: {}
  model_id: /storage/models/Llama-3.3-70B-Instruct
  name: Llama-3.3-70B-Instruct
  url: [[LLAMA70BV33_API_URL]]
metadata:
  __metadata_info__: {}
name: agent_7ced9454
outputs:
- default: 0
  title: result
  type: integer
system_prompt: You are an ancestry agent. Use tools to answer user questions. Make sure you generate an answer for the user, as the user cannot see the output of the tools. You must always mention the output of the tool to the user.
tools:
- component_type: ClientTool
  description: Fetches the name of the son/daughter of two people
  id: 9143dc8b-8068-4bca-b1c6-3b364b23cceb
  inputs:
  - title: first_parent
    type: string
  - title: second_parent
    type: string
  metadata:
    __metadata_info__: {}
  name: get_child
  outputs:
  - title: tool_output
    type: string
agentspec_version: "25.4.1"
