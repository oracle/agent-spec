# Copyright (C) 2024, 2025 Oracle and/or its affiliates.
#
# This software is under the Apache License 2.0
# (LICENSE-APACHE or http://www.apache.org/licenses/LICENSE-2.0) or Universal Permissive License
# (UPL) 1.0 (LICENSE-UPL or https://oss.oracle.com/licenses/upl), at your option.

"""This module defines several Agent Spec components."""

from typing import ClassVar, List

from pydantic import SerializeAsAny

from pyagentspec.flows.node import Node
from pyagentspec.llms.llmconfig import LlmConfig
from pyagentspec.property import Property, StringProperty
from pyagentspec.templating import get_placeholder_properties_from_string
from pyagentspec.versioning import AgentSpecVersionEnum


class LlmNode(Node):
    """
    Execute a prompt template with a given LLM.

    This node is intended to be a part of a Flow.

    - **Inputs**
        One per placeholder in the prompt template.
    - **Outputs**
        The output text generated by the LLM.

        If None is given, ``pyagentspec`` infers a string property named ``generated_text``.
    - **Branches**
        One, the default next.

    Example
    -------
    >>> from pyagentspec.property import Property
    >>> from pyagentspec.flows.flow import Flow
    >>> from pyagentspec.flows.edges import ControlFlowEdge, DataFlowEdge
    >>> from pyagentspec.flows.nodes import LlmNode, StartNode, EndNode
    >>> country_property = Property(
    ...     json_schema={"title": "country", "type": "string"}
    ... )
    >>> capital_property = Property(
    ...     json_schema={"title": "capital", "type": "string"}
    ... )
    >>> start_node = StartNode(name="start", inputs=[country_property])
    >>> end_node = EndNode(name="end", outputs=[capital_property])
    >>> llm_node = LlmNode(
    ...     name="simple llm node",
    ...     llm_config=llm_config,
    ...     prompt_template="What is the capital of {{ country }}?",
    ...     inputs=[country_property],
    ...     outputs=[capital_property],
    ... )
    >>> flow = Flow(
    ...     name="Get the country's capital flow",
    ...     start_node=start_node,
    ...     nodes=[start_node, llm_node, end_node],
    ...     control_flow_connections=[
    ...         ControlFlowEdge(name="start_to_llm", from_node=start_node, to_node=llm_node),
    ...         ControlFlowEdge(name="llm_to_end", from_node=llm_node, to_node=end_node),
    ...     ],
    ...     data_flow_connections=[
    ...         DataFlowEdge(
    ...             name="country_edge",
    ...             source_node=start_node,
    ...             source_output="country",
    ...             destination_node=llm_node,
    ...             destination_input="country",
    ...         ),
    ...         DataFlowEdge(
    ...             name="capital_edge",
    ...             source_node=llm_node,
    ...             source_output="capital",
    ...             destination_node=end_node,
    ...             destination_input="capital"
    ...         ),
    ...     ],
    ... )

    """

    llm_config: SerializeAsAny[LlmConfig]
    """The LLM to use for generation in this node."""
    prompt_template: str
    """Defines the prompt sent to the model. Allows placeholders, which can define inputs."""

    DEFAULT_OUTPUT: ClassVar[str] = "generated_text"
    """Raw text generated by the LLM."""

    def _get_inferred_inputs(self) -> List[Property]:
        return get_placeholder_properties_from_string(getattr(self, "prompt_template", ""))

    def _get_inferred_outputs(self) -> List[Property]:
        if self.outputs:
            return self.outputs
        output_title = self.outputs[0].title if self.outputs else self.DEFAULT_OUTPUT
        return [StringProperty(title=output_title, description="Raw text generated by the LLM")]

    def _infer_min_agentspec_version_from_configuration(self) -> "AgentSpecVersionEnum":
        if self.outputs:
            # We first check if the outputs require structured generation
            # (i.e., non-string property, or multiple properties)
            # If that's the case, we set the min version to 25.4.2, when structured gen was introduced
            if len(self.outputs) > 1 or self.outputs[0].type != "string":
                return AgentSpecVersionEnum.v25_4_2
        return super()._infer_min_agentspec_version_from_configuration()
